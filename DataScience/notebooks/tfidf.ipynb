{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8a83115",
   "metadata": {},
   "source": [
    "### **üîç ¬øQu√© es TF-IDF?**\n",
    "El `TF-IDF` es una t√©cnica usada en NLP (Procesamiento de Lenguaje Natural) que convierte texto en una **matriz num√©rica** e **indica qu√© tan importante es una palabra dentro de un documento** comparado con todos los documentos del corpus.\n",
    "\n",
    "![Descripci√≥n opcional](http://www.mblazquez.es/blog-ccdoc-recuperacion/formulas/formula05_ponderacion-tf-idf.png)\n",
    "<!--  -->\n",
    "TF-IDF significa:\n",
    "- **TF (Term Frequency):** cu√°ntas veces aparece una palabra en un documento.\n",
    "- **IDF (Inverse Document Frequency):** mide qu√© tan rara o informativa es una palabra en el corpus.\n",
    "\n",
    "#### **üß† F√≥rmulas**\n",
    "**TF(t, d)** = (Frecuencia del t√©rmino t en el documento d) / (Total de terminos en d)\n",
    "<!--  -->\n",
    "**IDF(t)** = log(N¬∫ total de documentos / N¬∫ de documentos que contienen el t√©rmino t)\n",
    "\n",
    "Entonces:\n",
    "\n",
    "**TF-IDF(t, d)** = TF(t, d) √ó IDF(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b6e91a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f313f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gato', 'negro']\n",
      "['gato', 'blanco']\n",
      "['perro', 'negro']\n",
      "\n",
      "['blanco', 'gato', 'negro', 'perro']\n",
      "\n",
      "[['gato', 'negro'], ['gato', 'blanco'], ['perro', 'negro']]\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    'el gato negro',\n",
    "    'el gato blanco',\n",
    "    'el perro negro'\n",
    "]\n",
    "\n",
    "# Stopwords -> Palabras muy comunes a eliminar para reducir ruido \n",
    "stopwords_es = {'el', 'en', 'la'}\n",
    "\n",
    "# Limpiar documentos (eliminar stopwords)\n",
    "tokenized_docs = []\n",
    "for doc in corpus:\n",
    "    words = doc.lower().split()\n",
    "    filtered = [word for word in words if word not in stopwords_es]\n",
    "    tokenized_docs.append(filtered)\n",
    "    print(filtered)\n",
    "\n",
    "# Crear vocabulario (palabras √∫nicas)\n",
    "vocab = sorted(set(word for doc in tokenized_docs for word in doc))\n",
    "print()\n",
    "print(vocab)\n",
    "print()\n",
    "print(tokenized_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a84e6ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blanco': 1.6931471805599454,\n",
       " 'gato': 1.2876820724517808,\n",
       " 'negro': 1.2876820724517808,\n",
       " 'perro': 1.6931471805599454}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IDF(t) = log(N¬∫ total de documentos / N¬∫ de documentos que contienen el t√©rmino t)\n",
    "def compute_idf(tokenized_docs):\n",
    "    idf = {}\n",
    "    N = len(tokenized_docs)\n",
    "    for term in vocab:\n",
    "        containing_docs = sum(1 for doc in tokenized_docs if term in doc)\n",
    "        idf[term] = math.log((1+N) / (1+containing_docs)) + 1  # +1 para evitar divisi√≥n por 0\n",
    "    return idf\n",
    "\n",
    "idf = compute_idf(tokenized_docs)\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5947890a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'blanco': 0.0, 'gato': 0.5, 'negro': 0.5, 'perro': 0.0},\n",
       " {'blanco': 0.5, 'gato': 0.5, 'negro': 0.0, 'perro': 0.0},\n",
       " {'blanco': 0.0, 'gato': 0.0, 'negro': 0.5, 'perro': 0.5}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF(t, d) = (N¬∫ de veces que el t√©rmino t aparece en el documento d)\n",
    "def compute_tf(doc_tokens):\n",
    "    tf = {}\n",
    "    total_terms = len(doc_tokens)\n",
    "    for term in vocab:\n",
    "        tf[term] = doc_tokens.count(term) / total_terms\n",
    "    return tf\n",
    "\n",
    "# Calcular TF-IDF por documento\n",
    "tf_dict = []\n",
    "\n",
    "for doc in tokenized_docs:\n",
    "    tf_doc = compute_tf(doc)\n",
    "    tf_dict.append(tf_doc)\n",
    "\n",
    "tf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4815fbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCABULARIO: ['blanco', 'gato', 'negro', 'perro']\n",
      "\n",
      "\n",
      "TF-IDF\n",
      "\n",
      "Documento 1\n",
      "blanco    : 0.000\n",
      "gato      : 0.707\n",
      "negro     : 0.707\n",
      "perro     : 0.000\n",
      "\n",
      "Documento 2\n",
      "blanco    : 0.796\n",
      "gato      : 0.605\n",
      "negro     : 0.000\n",
      "perro     : 0.000\n",
      "\n",
      "Documento 3\n",
      "blanco    : 0.000\n",
      "gato      : 0.000\n",
      "negro     : 0.605\n",
      "perro     : 0.796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.70710678, 0.70710678, 0.        ],\n",
       "       [0.79596054, 0.60534851, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.60534851, 0.79596054]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def l2_normalize(vector):\n",
    "    norm = math.sqrt(sum(v**2 for v in vector.values()))\n",
    "    if norm == 0:\n",
    "        return vector\n",
    "    return {k: v / norm for k, v in vector.items()}\n",
    "\n",
    "# Calcular TF-IDF por documento\n",
    "tfidf_vectors_dict = []\n",
    "tfidf_vectors = []\n",
    "\n",
    "for i, doc in enumerate(tokenized_docs):\n",
    "    tfidf = {term: tf_dict[i][term] * idf[term] for term in vocab}\n",
    "    tfidf = l2_normalize(tfidf)\n",
    "\n",
    "    tfidf_vectors_dict.append(tfidf)\n",
    "    tfidf_vectors.append(list(tfidf.values()))\n",
    "\n",
    "print('VOCABULARIO:', vocab)\n",
    "\n",
    "print('\\n\\nTF-IDF')\n",
    "for i, vec in enumerate(tfidf_vectors_dict):\n",
    "    print(f'\\nDocumento {i+1}')\n",
    "    for term in vocab:\n",
    "        print(f'{term:10}: {vec[term]:.3f}')\n",
    "\n",
    "np.array(tfidf_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e3a6ab",
   "metadata": {},
   "source": [
    "## **TfidfVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a87c928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCABULARIO: ['blanco' 'gato' 'negro' 'perro']\n",
      "\n",
      "[[0.         0.70710678 0.70710678 0.        ]\n",
      " [0.79596054 0.60534851 0.         0.        ]\n",
      " [0.         0.         0.60534851 0.79596054]]\n"
     ]
    }
   ],
   "source": [
    "# Stopwords\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=spanish_stopwords,\n",
    "                             norm='l2',\n",
    "                             use_idf=True,\n",
    "                             smooth_idf=True,\n",
    "                             sublinear_tf=False)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print('VOCABULARIO:', vectorizer.get_feature_names_out())\n",
    "print()\n",
    "print(X.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
